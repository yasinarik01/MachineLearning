{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ba32a1",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# üì¶ Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import combinations\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f63e8b0",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# ---------------------------------------------\n",
    "# üóÇÔ∏è Step 1: Load and visualize dataset\n",
    "# ---------------------------------------------\n",
    "columns = ['Variance', 'Skewness', 'Kurtosis', 'Entropy', 'Class']\n",
    "data_path = r\"C:\\Users\\Asus\\Desktop\\data_banknote_authentication.txt\"\n",
    "df = pd.read_csv(data_path, header=None, names=columns)\n",
    "\n",
    "# Feature pair scatter plots\n",
    "combs = list(combinations(columns[:-1], 2))\n",
    "plt.figure(figsize=(15, 10))\n",
    "for idx, (x, y) in enumerate(combs, 1):\n",
    "    plt.subplot(2, 3, idx)\n",
    "    sns.scatterplot(data=df, x=x, y=y, hue='Class', palette='Set2')\n",
    "    plt.title(f\"{x} vs {y}\")\n",
    "plt.suptitle(\"Feature Pair Visualizations\", fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e883efe",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# ---------------------------------------------\n",
    "# üßº Step 2: Preprocessing\n",
    "# ---------------------------------------------\n",
    "X = df.drop(\"Class\", axis=1)\n",
    "y = df[\"Class\"]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.2, random_state=42, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e9f55f",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# ---------------------------------------------\n",
    "# ‚úÖ Step 3: Evaluation Function (Fixed ‚Äì No Double Plots)\n",
    "# ---------------------------------------------\n",
    "def evaluate_model(clf, X_test, y_test, criterion, depth):\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    print(f\"\\nüìå Criterion: {criterion.upper()} | Max Depth: {depth}\")\n",
    "    print(\"---------------------------------------------------\")\n",
    "    print(classification_report(y_test, y_pred, digits=4))\n",
    "\n",
    "    # Proper confusion matrix (no double plot)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"Fake\", \"Authentic\"])\n",
    "    disp.plot(cmap='plasma')  # Yellow-purple color scheme\n",
    "    disp.ax_.set_title(f\"Confusion Matrix ({criterion}, depth={depth})\", fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43f1767",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# ---------------------------------------------\n",
    "# üîÅ Step 4: Try multiple hyperparameters\n",
    "# ---------------------------------------------\n",
    "criteria = [\"gini\", \"entropy\"]\n",
    "max_depths = [3, 5, 10]\n",
    "min_samples = [2, 5]\n",
    "\n",
    "for criterion in criteria:\n",
    "    for depth in max_depths:\n",
    "        for min_split in min_samples:\n",
    "            clf = DecisionTreeClassifier(\n",
    "                criterion=criterion,\n",
    "                max_depth=depth,\n",
    "                min_samples_split=min_split,\n",
    "                random_state=42\n",
    "            )\n",
    "            clf.fit(X_train, y_train)\n",
    "            evaluate_model(clf, X_test, y_test, criterion, depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba49f84",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# ---------------------------------------------\n",
    "# üå≥ Step 5: Final tree + feature importance\n",
    "# ---------------------------------------------\n",
    "def plot_final_tree_and_importance(clf, criterion_label):\n",
    "    # Tree visualization\n",
    "    plt.figure(figsize=(16, 8))\n",
    "    plot_tree(\n",
    "        clf,\n",
    "        feature_names=columns[:-1],\n",
    "        class_names=[\"Fake\", \"Authentic\"],\n",
    "        filled=True,\n",
    "        rounded=True\n",
    "    )\n",
    "    plt.title(f\"Decision Tree (criterion = '{criterion_label}')\", fontsize=14)\n",
    "    plt.show()\n",
    "\n",
    "    # Feature importance\n",
    "    importances = clf.feature_importances_\n",
    "    indices = np.argsort(importances)[::-1]\n",
    "    sorted_features = np.array(columns[:-1])[indices]\n",
    "\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    sns.barplot(x=importances[indices], y=sorted_features, palette='plasma')\n",
    "    plt.title(f\"Feature Importance (criterion = '{criterion_label}')\", fontsize=13)\n",
    "    plt.xlabel(\"Importance Score\")\n",
    "    plt.ylabel(\"Features\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed54676",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Final models\n",
    "final_entropy = DecisionTreeClassifier(criterion=\"entropy\", max_depth=5, random_state=42)\n",
    "final_entropy.fit(X_train, y_train)\n",
    "plot_final_tree_and_importance(final_entropy, \"entropy\")\n",
    "\n",
    "final_gini = DecisionTreeClassifier(criterion=\"gini\", max_depth=5, random_state=42)\n",
    "final_gini.fit(X_train, y_train)\n",
    "plot_final_tree_and_importance(final_gini, \"gini\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
